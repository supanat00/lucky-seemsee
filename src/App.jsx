import { useCallback, useEffect, useRef, useState } from 'react'
import { Muxer, ArrayBufferTarget } from 'mp4-muxer'
import { createCorrectBlob } from './utils/videoUtils'
import { detectBrowserAndPlatform, isAndroid, isChrome, getVideoMimeTypes } from './utils/deviceUtils'
import { buildAiWallpaperPrompt } from './utils/aiWallpaperPrompt'
import { generateImageFromPrompt } from './services/openaiImageApi'
import { getLineUserId, initLiff, isInLine } from './services/liffService'
import { uploadImageToCloudinary } from './services/cloudinaryService'
import { mockGenerateAndUploadAiWallpaper } from './services/aiWallpaperMock'
import './App.css'
import CameraStage from './components/CameraStage'
import HomeScreen from './components/HomeScreen'
import HorseScreen from './components/HorseScreen'
import ShakeScreen from './components/ShakeScreen'
import FortuneScreen from './components/FortuneScreen'
import WallpaperScreen from './components/WallpaperScreen'
import horseModel from './assets/models/house_test.glb'
import wish01 from './assets/horse_fire/wish01.png'
import wish02 from './assets/horse_fire/wish02.png'
import wish03 from './assets/horse_fire/wish03.png'
import wish04 from './assets/horse_fire/wish04.png'
import wish05 from './assets/horse_fire/wish05.png'
import wishPropRImg from './assets/horse_fire/wish_prop_r.png'
import wishPropLImg from './assets/horse_fire/wish_prop_l.png'
import head1 from './assets/head_text/head_text01.png'
import head2 from './assets/head_text/head_text02.png'
import head3 from './assets/head_text/head_text03.png'
import head4 from './assets/head_text/head_text04.png'
import head5 from './assets/head_text/head_text05.png'
import text1 from './assets/text/text01.png'
import text2 from './assets/text/text02.png'
import text3 from './assets/text/text03.png'
import text4 from './assets/text/text04.png'
import text5 from './assets/text/text05.png'

const HORSE_WISH_IMAGES = [wish01, wish02, wish03, wish04, wish05]

const WALLPAPER_TOPIC_OPTIONS = [
  { value: 'health', label: '‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û' },
  { value: 'love', label: '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏Å' },
  { value: 'career', label: '‡∏Å‡∏≤‡∏£‡∏á‡∏≤‡∏ô' },
  { value: 'money', label: '‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô' },
]

const WALLPAPER_ZODIAC_OPTIONS = [
  { value: 'rat', label: '‡∏ä‡∏ß‡∏î' },
  { value: 'ox', label: '‡∏â‡∏•‡∏π' },
  { value: 'tiger', label: '‡∏Ç‡∏≤‡∏•' },
  { value: 'rabbit', label: '‡πÄ‡∏ñ‡∏≤‡∏∞' },
  { value: 'dragon', label: '‡∏°‡∏∞‡πÇ‡∏£‡∏á' },
  { value: 'snake', label: '‡∏°‡∏∞‡πÄ‡∏™‡πá‡∏á' },
  { value: 'horse', label: '‡∏°‡∏∞‡πÄ‡∏°‡∏µ‡∏¢' },
  { value: 'goat', label: '‡∏°‡∏∞‡πÅ‡∏°' },
  { value: 'monkey', label: '‡∏ß‡∏≠‡∏Å' },
  { value: 'rooster', label: '‡∏£‡∏∞‡∏Å‡∏≤' },
  { value: 'dog', label: '‡∏à‡∏≠' },
  { value: 'pig', label: '‡∏Å‡∏∏‡∏ô' },
]

/**
 * Main App Component
 * ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ routing, state management, ‡πÅ‡∏•‡∏∞ camera logic
 */
function App() {
  // ============================================
  // STATE MANAGEMENT
  // ============================================

  /** ‡∏´‡∏ô‡πâ‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô: 'home' | 'shake' | 'horse' | 'fortune' | 'wallpaper' */
  const [view, setView] = useState('home')

  /** ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° error ‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á */
  const [cameraError, setCameraError] = useState('')

  /** ‡πÇ‡∏´‡∏°‡∏î‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û: 'photo' | 'video' */
  const [captureMode, setCaptureMode] = useState('photo')

  /** ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ */
  const [isRecording, setIsRecording] = useState(false)

  /** ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à */
  const [isProcessing, setIsProcessing] = useState(false)

  /** Preview ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û/‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢: { type: 'photo' | 'video' | null, url: string | null } */
  const [preview, setPreview] = useState({ type: null, url: null })

  /** Wish image ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ horse (‡∏ï‡πâ‡∏≠‡∏á deterministic ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ output ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á) */
  const [selectedWishSrc, setSelectedWishSrc] = useState(HORSE_WISH_IMAGES[0])

  /** Trigger ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡∏¢‡πà‡∏≤‡πÄ‡∏ã‡∏µ‡∏¢‡∏°‡∏ã‡∏µ (increment ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡∏¢‡πà‡∏≤) */
  const [shakeTrigger, setShakeTrigger] = useState(0)

  /** Index ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ã‡∏µ‡∏¢‡∏°‡∏ã‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ (0-4) */
  const [fortuneIndex, setFortuneIndex] = useState(null)

  /** ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏î‡∏ß‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏≠‡∏•‡πÄ‡∏õ‡πÄ‡∏õ‡∏≠‡∏£‡πå */
  const [selectedTopic, setSelectedTopic] = useState('')

  /** ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏µ‡∏ô‡∏±‡∏Å‡∏©‡∏±‡∏ï‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏≠‡∏•‡πÄ‡∏õ‡πÄ‡∏õ‡∏≠‡∏£‡πå */
  const [selectedZodiac, setSelectedZodiac] = useState('')

  /** AI wallpaper mock state */
  const [aiWallpaperStatus, setAiWallpaperStatus] = useState('idle') // 'idle' | 'generating' | 'ready' | 'error'
  const [aiWallpaperResult, setAiWallpaperResult] = useState(null)
  const [aiWallpaperError, setAiWallpaperError] = useState('')

  // ============================================
  // REFS
  // ============================================

  /** ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡∏¢‡πà‡∏≤‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏¢‡πà‡∏≤‡∏ã‡πâ‡∏≥) */
  const lastShakeTimeRef = useRef(0)

  /** Reference ‡πÑ‡∏õ‡∏¢‡∏±‡∏á video element */
  const videoRef = useRef(null)

  /** Reference ‡πÑ‡∏õ‡∏¢‡∏±‡∏á camera stream */
  const streamRef = useRef(null)

  /** Reference ‡πÑ‡∏õ‡∏¢‡∏±‡∏á MediaRecorder */
  const mediaRecorderRef = useRef(null)

  /** Chunks ‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å */
  const recordedChunksRef = useRef([])

  /** Timeout ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ (30 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ) */
  const recordingTimeoutRef = useRef(null)

  /** Reference ‡πÑ‡∏õ‡∏¢‡∏±‡∏á container ‡∏Ç‡∏≠‡∏á HorseScreen (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AR capture) */
  const horseContainerRef = useRef(null)

  /** Reference ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Three.js Canvas (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AR capture) */
  const threeCanvasRef = useRef(null)

  /** Reference ‡πÑ‡∏õ‡∏¢‡∏±‡∏á composite canvas ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö video recording */
  const compositeCanvasRef = useRef(null)

  /** Animation frame ID ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö video recording */
  const recordingAnimationFrameRef = useRef(null)

  /** Refs ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö mp4-muxer (Android/Chrome) */
  const muxerRef = useRef(null)
  const videoEncoderRef = useRef(null)
  const audioEncoderRef = useRef(null)
  const isRecordingRef = useRef(false)
  const audioTrackRef = useRef(null)
  const audioSourceNodeRef = useRef(null)
  const audioProcessorNodeRef = useRef(null)
  const audioStreamRef = useRef(null)

  /** Cache ‡∏£‡∏π‡∏õ overlay ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏ã‡πâ‡∏≥ */
  const overlayImageCacheRef = useRef(new Map())

  const loadOverlayImage = useCallback((src) => {
    if (!src) return Promise.resolve(null)

    const cached = overlayImageCacheRef.current.get(src)
    if (cached) return cached

    const promise = new Promise((resolve, reject) => {
      const img = new Image()
      img.onload = () => resolve(img)
      img.onerror = () => reject(new Error(`Failed to load overlay image: ${src}`))
      img.src = src
    })

    overlayImageCacheRef.current.set(src, promise)
    return promise
  }, [])

  const drawHorseOverlayFixed = useCallback((ctx, W, H, wishImg, propRImg, propLImg) => {
    if (!ctx) return

    // === Wish image (match existing design but deterministic in 720x1280 space) ===
    if (wishImg?.naturalWidth && wishImg?.naturalHeight) {
      const wishW = W * 1.3
      const wishX = W * 0.5 - wishW * 0.42
      // ‡∏Ç‡∏¢‡∏±‡∏ö‡∏Ç‡∏∂‡πâ‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏≠‡∏µ‡∏Å‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ preview (match CSS padding-top: 40px)
      const wishY = 40
      const wishH = wishW * (wishImg.naturalHeight / wishImg.naturalWidth)
      ctx.drawImage(
        wishImg,
        Math.round(wishX),
        Math.round(wishY),
        Math.round(wishW),
        Math.round(wishH)
      )
    }

    // === Props (match CSS: bottom 12%, widths 38%/40% + translateX) ===
    if (propRImg?.naturalWidth && propRImg?.naturalHeight) {
      const w = W * 0.38
      const h = w * (propRImg.naturalHeight / propRImg.naturalWidth)
      const x = W - 0.7 * w // right:0 + translateX(30%) => W - w + 0.3w = W - 0.7w
      // ‡∏Ç‡∏¢‡∏±‡∏ö prop ‡∏Ç‡∏ß‡∏≤‡∏•‡∏á‡∏≠‡∏µ‡∏Å‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (match CSS bottom: 8%)
      const y = H * (1 + 0.015) - h
      ctx.drawImage(propRImg, Math.round(x), Math.round(y), Math.round(w), Math.round(h))
    }

    if (propLImg?.naturalWidth && propLImg?.naturalHeight) {
      const w = W * 0.4
      const h = w * (propLImg.naturalHeight / propLImg.naturalWidth)
      const x = -0.60 * w // left:0 + translateX(-50%)
      const y = H * (1 - 0.12) - h
      ctx.drawImage(propLImg, Math.round(x), Math.round(y), Math.round(w), Math.round(h))
    }
  }, [])

  // ============================================
  // EVENT HANDLERS
  // ============================================

  /**
   * ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏¢‡πà‡∏≤‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
   * ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏£‡∏á‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏¢‡πà‡∏≤‡πÅ‡∏•‡∏∞ trigger sequence
   */
  const handleShake = useCallback((event) => {
    const acc = event.accelerationIncludingGravity || event.acceleration
    if (!acc) return

    const x = acc.x || 0
    const y = acc.y || 0
    const z = acc.z || 0

    const magnitude = Math.sqrt(x * x + y * y + z * z)
    const now = Date.now()
    const threshold = 15 // ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏£‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
    const minInterval = 800 // ‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏¢‡πà‡∏≤ (ms)

    if (magnitude > threshold && now - lastShakeTimeRef.current > minInterval) {
      lastShakeTimeRef.current = now
      setShakeTrigger((v) => v + 1)
    }
  }, [])

  // ============================================
  // EFFECTS
  // ============================================

  /**
   * ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ DeviceMotion listener ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤ shake
   */
  useEffect(() => {
    if (view !== 'shake') return

    window.addEventListener('devicemotion', handleShake)
    return () => {
      window.removeEventListener('devicemotion', handleShake)
    }
  }, [handleShake, view])

  /**
   * ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå model-viewer ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤ horse)
   */
  useEffect(() => {
    if (window.customElements?.get('model-viewer')) return
    const script = document.createElement('script')
    script.type = 'module'
    script.src = 'https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js'
    document.head.appendChild(script)
  }, [])

  /**
   * Preload ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡πâ‡∏≤‡πÑ‡∏ü‡πÑ‡∏ß‡πâ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤
   */
  useEffect(() => {
    fetch(horseModel).catch((err) => {
      console.error('preload horse model failed', err)
    })
  }, [])

  /**
   * ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÅ‡∏≠‡∏õ
   */
  useEffect(() => {
    async function startCamera() {
      try {
        if (streamRef.current) return
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: { ideal: 'user' } },
          audio: false,
        })
        streamRef.current = stream
        if (videoRef.current) {
          videoRef.current.srcObject = stream
        }
        setCameraError('')
      } catch (err) {
        console.error(err)
        setCameraError('‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏î‡πâ ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö permission ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå')
      }
    }

    startCamera()

    return () => {
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((t) => t.stop())
        streamRef.current = null
      }
    }
  }, [])

  // Init LIFF once (safe no-op in normal browsers when VITE_LIFF_ID not set)
  useEffect(() => {
    initLiff().catch(() => null)
  }, [])

  /**
   * ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï srcObject ‡πÄ‡∏°‡∏∑‡πà‡∏≠ videoRef ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô
   */
  useEffect(() => {
    if (videoRef.current && streamRef.current) {
      videoRef.current.srcObject = streamRef.current
    }
  }, [videoRef])

  // ============================================
  // NAVIGATION FUNCTIONS
  // ============================================

  /**
   * ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å
   * ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î state ‡πÅ‡∏•‡∏∞‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
   */
  const goHome = () => {
    // Stop recording if active
    if (isRecording && mediaRecorderRef.current) {
      try {
        if (mediaRecorderRef.current.state !== 'inactive') {
          mediaRecorderRef.current.stop()
        }
      } catch (err) {
        console.error('Error stopping recorder:', err)
      }
    }
    setIsRecording(false)
    if (recordingTimeoutRef.current) {
      clearTimeout(recordingTimeoutRef.current)
      recordingTimeoutRef.current = null
    }
    setPreview({ type: null, url: null })
    // reset wallpaper selections so user can "play again" without confusion
    setSelectedTopic('')
    setSelectedZodiac('')
    setAiWallpaperStatus('idle')
    setAiWallpaperResult(null)
    setAiWallpaperError('')
    setShakeTrigger(0)
    setView('home')
  }

  /**
   * ‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏Ç‡∏¢‡πà‡∏≤‡πÄ‡∏ã‡∏µ‡∏¢‡∏°‡∏ã‡∏µ
   * ‡∏Ç‡∏≠ permission ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DeviceMotion (iOS) ‡πÅ‡∏•‡∏∞‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï state
   */
  const goToShake = async () => {
    try {
      const DeviceMotionEventRef = window.DeviceMotionEvent
      if (DeviceMotionEventRef && typeof DeviceMotionEventRef.requestPermission === 'function') {
        await DeviceMotionEventRef.requestPermission().catch(() => null)
      }
    } catch (err) {
      console.error(err)
    }
    setShakeTrigger(0)
    lastShakeTimeRef.current = 0
    setView('shake')
  }

  /**
   * ‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏°‡∏á‡∏Ñ‡∏•
   * ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï preview ‡πÅ‡∏•‡∏∞ recording state
   */
  const goToHorse = () => {
    setPreview({ type: null, url: null })
    setIsRecording(false)
    setCaptureMode('photo')
    // ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å wish ‡πÉ‡∏´‡πâ‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö session ‡∏ô‡∏µ‡πâ (photo+video ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)
    const randomWish = HORSE_WISH_IMAGES[Math.floor(Math.random() * HORSE_WISH_IMAGES.length)]
    setSelectedWishSrc(randomWish)
    setView('horse')
  }

  /**
   * ‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÄ‡∏ã‡∏µ‡∏¢‡∏°‡∏ã‡∏µ
   * ‡∏™‡∏∏‡πà‡∏° index ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ã‡∏µ‡∏¢‡∏°‡∏ã‡∏µ (0-4)
   */
  const goToFortune = () => {
    const idx = Math.floor(Math.random() * 5)
    setFortuneIndex(idx)
    setView('fortune')
  }

  /**
   * ‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏≠‡∏•‡πÄ‡∏õ‡πÄ‡∏õ‡∏≠‡∏£‡πå
   */
  const goToWallpaper = () => {
    // reset to blank defaults every time user enters this step
    setSelectedTopic('')
    setSelectedZodiac('')
    setAiWallpaperStatus('idle')
    setAiWallpaperResult(null)
    setAiWallpaperError('')
    setView('wallpaper')
  }

  const handleCreateAiWallpaper = useCallback(async () => {
    if (!selectedTopic || !selectedZodiac) return
    if (aiWallpaperStatus === 'generating') return

    const topicOpt = WALLPAPER_TOPIC_OPTIONS.find((o) => o.value === selectedTopic)
    const zodiacOpt = WALLPAPER_ZODIAC_OPTIONS.find((o) => o.value === selectedZodiac)
    const prompt = buildAiWallpaperPrompt({
      topicValue: selectedTopic,
      topicLabel: topicOpt?.label || selectedTopic,
      zodiacValue: selectedZodiac,
      zodiacLabel: zodiacOpt?.label || selectedZodiac,
    })

    console.log('üß† AI Wallpaper prompt:', prompt)

    setAiWallpaperError('')
    setAiWallpaperResult(null)
    setAiWallpaperStatus('generating')
    try {
      // IMPORTANT: Save credits.
      // - LINE LIFF: use REAL OpenAI + REAL Cloudinary upload.
      // - Normal browsers (Android/Chrome, iOS/Safari, desktop): use MOCK images for now.
      try {
        await initLiff()
      } catch {
        // ignore
      }

      if (!isInLine()) {
        const mock = await mockGenerateAndUploadAiWallpaper({ prompt })
        setAiWallpaperResult(mock)
        setAiWallpaperStatus('ready')
        return
      }

      // 1) Generate image (REAL) - LIFF only
      const gen = await generateImageFromPrompt(prompt)
      if (!gen.success || !gen.base64) {
        throw new Error(gen.error || '‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û')
      }

      // 2) Upload to Cloudinary BEFORE showing preview (so preview can open link immediately)
      const userId = await getLineUserId()
      const publicId = userId ? `lucky_seemsee_wallpaper_${userId}` : 'lucky_seemsee_wallpaper_default'
      const up = await uploadImageToCloudinary({
        dataUrl: gen.base64,
        folder: 'lucky-seemsee',
        publicId,
      })
      if (!up.success || !up.url) {
        throw new Error(up.error || '‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏õ‡∏¢‡∏±‡∏á Cloudinary ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à')
      }

      // Cache busting for external browser:
      // Even if we overwrite the same public_id, external browsers/CDNs can serve a cached (old) image.
      // Cloudinary returns a "version" on upload; use it (fallback to timestamp) to force a fresh URL.
      // Use ms-level cache busting to avoid "old image" when multiple overwrites happen quickly
      // (Cloudinary version can be second-level; LINE/external browser can aggressively cache).
      const cacheKey = `${up.version || '0'}-${Date.now()}`
      const cloudUrl = `${up.url}${up.url.includes('?') ? '&' : '?'}cb=${encodeURIComponent(cacheKey)}`

      setAiWallpaperResult({
        imageSrc: gen.base64,
        cloudUrl,
        prompt,
        revisedPrompt: gen.revisedPrompt || null,
      })
      setAiWallpaperStatus('ready')
    } catch (e) {
      console.error('AI wallpaper failed:', e)
      setAiWallpaperError(e?.message || '‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û')
      setAiWallpaperStatus('error')
    }
  }, [aiWallpaperStatus, selectedTopic, selectedZodiac])

  const handleAiWallpaperPlayAgain = () => {
    // ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    goHome()
  }

  // ============================================
  // CAPTURE FUNCTIONS
  // ============================================

  /**
   * ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÅ‡∏ö‡∏ö AR (‡∏£‡∏ß‡∏° video + 3D model + decorative elements)
   * ‡∏Å‡∏•‡∏±‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á
   */
  const capturePhoto = async () => {
    if (!videoRef.current || !horseContainerRef.current) return

    try {
      const videoEl = videoRef.current
      const container = horseContainerRef.current

      if (videoEl.readyState < 2) {
        await new Promise((resolve) => {
          videoEl.addEventListener('loadeddata', resolve, { once: true })
        })
      }

      // ‡∏™‡∏£‡πâ‡∏≤‡∏á canvas ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö composite - ‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á 9:16
      // ‡πÉ‡∏ä‡πâ 720x1280 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏ô AVC level 3.1 limit (921,600 pixels)
      const canvas = document.createElement('canvas')
      const OUTPUT_WIDTH = 720
      const OUTPUT_HEIGHT = 1280
      canvas.width = OUTPUT_WIDTH
      canvas.height = OUTPUT_HEIGHT
      const ctx = canvas.getContext('2d')

      // 1. ‡∏ß‡∏≤‡∏î video stream ‡∏Å‡πà‡∏≠‡∏ô (‡πÄ‡∏ï‡πá‡∏° canvas 720x1280)
      const videoWidth = videoEl.videoWidth || OUTPUT_WIDTH
      const videoHeight = videoEl.videoHeight || OUTPUT_HEIGHT
      const videoAspect = videoWidth / videoHeight

      // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î video ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡πá‡∏° canvas ‡πÇ‡∏î‡∏¢‡∏¢‡∏∂‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å (9:16)
      let bgWidth = OUTPUT_WIDTH
      let bgHeight = bgWidth / videoAspect
      if (bgHeight < OUTPUT_HEIGHT) {
        bgHeight = OUTPUT_HEIGHT
        bgWidth = bgHeight * videoAspect
      }
      const bgX = (OUTPUT_WIDTH - bgWidth) / 2
      const bgY = (OUTPUT_HEIGHT - bgHeight) / 2

      // Mirror ‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤)
      ctx.save()
      ctx.translate(OUTPUT_WIDTH, 0)
      ctx.scale(-1, 1) // mirror ‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô
      ctx.drawImage(videoEl, bgX, bgY, bgWidth, bgHeight)
      ctx.restore()

      // 2. ‡∏ß‡∏≤‡∏î decorative elements ‡πÅ‡∏ö‡∏ö deterministic ‡πÉ‡∏ô output 720x1280 (‡πÑ‡∏°‡πà‡∏≠‡∏¥‡∏á DOM)
      const [wishImg, propRImg, propLImg] = await Promise.all([
        loadOverlayImage(selectedWishSrc),
        loadOverlayImage(wishPropRImg),
        loadOverlayImage(wishPropLImg),
      ])
      drawHorseOverlayFixed(ctx, OUTPUT_WIDTH, OUTPUT_HEIGHT, wishImg, propRImg, propLImg)

      // 3. ‡∏ß‡∏≤‡∏î Three.js canvas (3D model) ‡∏ó‡∏±‡∏ö
      // ‡πÉ‡∏ä‡πâ threeCanvasRef ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö gl.domElement ‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß
      // ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö noodleverse: ‡πÉ‡∏ä‡πâ canvas size ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡πá‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á
      const threeCanvasEl = threeCanvasRef.current
      if (threeCanvasEl && threeCanvasEl.width > 0 && threeCanvasEl.height > 0) {
        // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì aspect ratio ‡∏Ç‡∏≠‡∏á Three.js canvas
        const arAspectRatio = threeCanvasEl.width / threeCanvasEl.height

        // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏°‡πà‡∏Ç‡∏≠‡∏á Three.js canvas ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ß‡∏≤‡∏î‡∏•‡∏á‡πÑ‡∏õ ‡πÇ‡∏î‡∏¢‡∏¢‡∏∂‡∏î "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á" ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
        const drawHeight = OUTPUT_HEIGHT // ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡πÄ‡∏ï‡πá‡∏° 1280px
        const drawWidth = drawHeight * arAspectRatio // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏°‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏î‡∏¥‡∏°

        // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏†‡∏≤‡∏û‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á
        const drawX = (OUTPUT_WIDTH - drawWidth) / 2

        // ‡∏ß‡∏≤‡∏î Three.js canvas ‡∏•‡∏á‡πÑ‡∏õ‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á ‡πÇ‡∏î‡∏¢‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÑ‡∏°‡πà‡∏•‡πâ‡∏ô‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á
        ctx.drawImage(threeCanvasEl, drawX, 0, drawWidth, drawHeight)
        console.log('‚úÖ Three.js canvas drawn successfully:', drawX, 0, drawWidth, drawHeight)
      } else {
        console.warn('‚ùå Three.js canvas element not found or has invalid size:', threeCanvasEl)
        // Fallback: ‡∏•‡∏≠‡∏á query ‡∏à‡∏≤‡∏Å DOM
        const modelFrame = container.querySelector('.model-frame')
        if (modelFrame) {
          const fallbackCanvas = modelFrame.querySelector('canvas')
          if (fallbackCanvas && fallbackCanvas.width > 0 && fallbackCanvas.height > 0) {
            console.log('Using fallback canvas from DOM')
            const arAspectRatio = fallbackCanvas.width / fallbackCanvas.height
            const drawHeight = OUTPUT_HEIGHT
            const drawWidth = drawHeight * arAspectRatio
            const drawX = (OUTPUT_WIDTH - drawWidth) / 2
            ctx.drawImage(fallbackCanvas, drawX, 0, drawWidth, drawHeight)
          }
        }
      }

      // canvas ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÅ‡∏•‡πâ‡∏ß (‡∏°‡∏µ video + decorative elements + 3D model)

      const dataUrl = canvas.toDataURL('image/png')
      setPreview({ type: 'photo', url: dataUrl })
    } catch (error) {
      console.error('Error capturing photo:', error)
      setCameraError('‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ')
    }
  }

  /**
   * ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ mp4-muxer (Android/Chrome)
   */
  const startRecordingWithMuxer = useCallback(async () => {
    // ‡πÉ‡∏ä‡πâ‡∏Ç‡∏ô‡∏≤‡∏î 720x1280 (9:16 portrait) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏ô AVC level 3.1 limit (921,600 pixels)
    // 720x1280 = 921,600 pixels (‡∏û‡∏≠‡∏î‡∏µ limit)
    let videoWidth = 720
    let videoHeight = 1280

    if (videoWidth % 2 !== 0) videoWidth++
    if (videoHeight % 2 !== 0) videoHeight++

    muxerRef.current = new Muxer({
      target: new ArrayBufferTarget(),
      video: { codec: 'avc', width: videoWidth, height: videoHeight },
      audio: { codec: 'aac', sampleRate: 44100, numberOfChannels: 1 },
      fastStart: 'in-memory',
    })

    videoEncoderRef.current = new VideoEncoder({
      output: (chunk, meta) => muxerRef.current.addVideoChunk(chunk, meta),
      error: (e) => console.error('VideoEncoder error:', e),
    })
    await videoEncoderRef.current.configure({
      codec: 'avc1.42001f', // AVC level 3.1 (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ñ‡∏∂‡∏á 921,600 pixels)
      width: videoWidth,
      height: videoHeight,
      bitrate: 3_000_000, // ‡πÉ‡∏ä‡πâ bitrate ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö noodleverse ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤
    })

    const audioContext = new (window.AudioContext || window.webkitAudioContext)()
    const sampleRate = audioContext.sampleRate

    // ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏£‡∏±‡∏ö audio stream ‡∏à‡∏≤‡∏Å microphone
    let lastAudioTimestamp = 0

    try {
      const audioStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      })

      audioStreamRef.current = audioStream

      const audioSourceNode = audioContext.createMediaStreamSource(audioStream)
      audioSourceNodeRef.current = audioSourceNode

      const bufferSize = 4096
      const audioProcessorNode = audioContext.createScriptProcessor(bufferSize, 1, 1)
      audioProcessorNodeRef.current = audioProcessorNode

      audioProcessorNode.onaudioprocess = (event) => {
        if (!isRecordingRef.current || !audioEncoderRef.current) return

        const inputBuffer = event.inputBuffer
        const inputData = inputBuffer.getChannelData(0)

        // ‡∏™‡∏£‡πâ‡∏≤‡∏á AudioData ‡πÅ‡∏•‡∏∞ encode
        try {
          const audioData = new AudioData({
            timestamp: lastAudioTimestamp,
            data: inputData,
            numberOfFrames: inputData.length,
            numberOfChannels: 1,
            sampleRate: sampleRate,
            format: 'f32-planar'
          })

          if (audioEncoderRef.current?.state === 'configured') {
            audioEncoderRef.current.encode(audioData)
            lastAudioTimestamp += Math.round((inputData.length / sampleRate) * 1_000_000) // microseconds
          }

          audioData.close()
        } catch (err) {
          console.error('Error encoding audio:', err)
        }
      }

      audioSourceNode.connect(audioProcessorNode)
      audioProcessorNode.connect(audioContext.destination)

      audioTrackRef.current = audioStream.getAudioTracks()[0]
      console.log('‚úÖ Audio stream connected for muxer recording')
    } catch (audioError) {
      console.warn("‚ö†Ô∏è Audio permission denied or not available, recording without audio:", audioError)
      // ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ audio stream ‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á
    }

    audioEncoderRef.current = new AudioEncoder({
      output: (chunk, meta) => muxerRef.current.addAudioChunk(chunk, meta),
      error: (e) => console.error('AudioEncoder error:', e),
    })
    await audioEncoderRef.current.configure({
      codec: 'mp4a.40.2',
      sampleRate: sampleRate,
      numberOfChannels: 1,
      bitrate: 96000,
    })

    let recordingStartTime = null

    const processFrame = (currentTime) => {
      if (!isRecordingRef.current) return
      if (recordingStartTime === null) recordingStartTime = currentTime

      // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ compositeCanvas ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
      if (!compositeCanvasRef.current) {
        recordingAnimationFrameRef.current = requestAnimationFrame(processFrame)
        return
      }

      // ‡∏™‡πà‡∏á Frame ‡πÑ‡∏õ Encode
      if (videoEncoderRef.current?.state === 'configured') {
        const elapsedTimeMs = currentTime - recordingStartTime
        const timestamp = Math.round(elapsedTimeMs * 1000)

        try {
          // ‡πÉ‡∏ä‡πâ compositeCanvas ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (‡∏Ç‡∏ô‡∏≤‡∏î 720x1280)
          // compositeCanvas ‡∏ñ‡∏π‡∏Å‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÇ‡∏î‡∏¢ compositeFrame loop
          const videoFrame = new VideoFrame(compositeCanvasRef.current, { timestamp })
          if (videoFrame) {
            videoEncoderRef.current.encode(videoFrame)
          }
          videoFrame.close()
        } catch (err) {
          console.error('Error creating/encoding VideoFrame:', err)
        }
      }

      recordingAnimationFrameRef.current = requestAnimationFrame(processFrame)
    }
    requestAnimationFrame(processFrame)
    return true
  }, [])

  /**
   * ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ MediaRecorder (browser ‡∏≠‡∏∑‡πà‡∏ô‡πÜ)
   */
  const startRecordingWithMediaRecorder = useCallback(async () => {
    if (!compositeCanvasRef.current) return false

    const videoStream = compositeCanvasRef.current.captureStream(30)

    let audioStream = null
    let audioTrack = null
    try {
      audioStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      })
      audioTrack = audioStream.getAudioTracks()[0]
      audioTrackRef.current = audioTrack
    } catch (audioError) {
      console.warn("Audio permission denied or not available, recording without audio:", audioError)
    }

    const streamTracks = [...videoStream.getVideoTracks()]
    if (audioTrack) {
      streamTracks.push(audioTrack)
    }
    const combinedStream = new MediaStream(streamTracks)

    const mimeTypes = getVideoMimeTypes()
    const { isIOS, isSafari, isChrome } = detectBrowserAndPlatform()

    let selectedMimeType = null
    for (const mimeType of mimeTypes) {
      if (MediaRecorder.isTypeSupported(mimeType)) {
        selectedMimeType = mimeType
        break
      }
    }

    if (!selectedMimeType) {
      if (isIOS || isSafari) {
        selectedMimeType = 'video/mp4'
      } else if (isChrome) {
        selectedMimeType = 'video/mp4'
      } else {
        selectedMimeType = 'video/mp4'
      }
    }

    const options = selectedMimeType ? { mimeType: selectedMimeType } : {}

    mediaRecorderRef.current = new MediaRecorder(combinedStream, options)
    recordedChunksRef.current = []

    mediaRecorderRef.current.ondataavailable = (event) => {
      if (event.data && event.data.size > 0) {
        recordedChunksRef.current.push(event.data)
        console.log(`Received chunk: ${(event.data.size / 1024).toFixed(2)}KB, Total chunks: ${recordedChunksRef.current.length}`)
      }
    }

    mediaRecorderRef.current.onerror = (event) => {
      console.error("MediaRecorder error:", event.error)
      setCameraError("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
      if (audioTrackRef.current) {
        audioTrackRef.current.stop()
        audioTrackRef.current = null
      }
      setIsRecording(false)
    }

    // ‡πÄ‡∏Å‡πá‡∏ö reference ‡πÑ‡∏õ‡∏¢‡∏±‡∏á canvas ‡∏Ç‡∏≠‡∏á session ‡∏ô‡∏µ‡πâ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô closure ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô race condition
    const sessionCanvas = compositeCanvasRef.current

    mediaRecorderRef.current.onstop = async () => {
      setIsRecording(false)
      isRecordingRef.current = false
      if (recordingAnimationFrameRef.current) {
        cancelAnimationFrame(recordingAnimationFrameRef.current)
        recordingAnimationFrameRef.current = null
      }

      // ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
      setIsProcessing(true)

      try {
        const actualMimeType = mediaRecorderRef.current?.mimeType
        let finalMimeType = actualMimeType
        if (!finalMimeType || finalMimeType === 'video/webm') {
          const { isIOS, isSafari, isChrome } = detectBrowserAndPlatform()
          if (isIOS || isSafari) {
            finalMimeType = 'video/mp4'
          } else if (isChrome) {
            finalMimeType = 'video/mp4'
          } else {
            finalMimeType = 'video/mp4'
          }
        }

        // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ chunks ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        if (recordedChunksRef.current.length === 0) {
          throw new Error("No video chunks recorded")
        }

        const totalSize = recordedChunksRef.current.reduce((sum, chunk) => sum + chunk.size, 0)
        console.log(`Total chunks: ${recordedChunksRef.current.length}, Total size: ${(totalSize / 1024 / 1024).toFixed(2)}MB`)

        const videoBlob = createCorrectBlob(recordedChunksRef.current, finalMimeType)

        if (videoBlob.size === 0) {
          throw new Error("Recorded video is empty")
        }

        console.log(`Video blob size: ${(videoBlob.size / 1024 / 1024).toFixed(2)}MB`)
        console.log(`Video blob type: ${videoBlob.type}`)

        // ‡∏™‡∏£‡πâ‡∏≤‡∏á video URL ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á preview ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á test playability
        // ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ timeout ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏î‡πâ‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡πÄ‡∏•‡πà‡∏ô‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
        const videoUrl = URL.createObjectURL(videoBlob)
        setPreview({ type: 'video', url: videoUrl, mimeType: finalMimeType })

        console.log(`‚úÖ Video recorded successfully: ${(videoBlob.size / 1024 / 1024).toFixed(2)}MB`)
      } catch (processingError) {
        console.error("Error processing video:", processingError)
        setCameraError("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
      } finally {
        setIsProcessing(false) // ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        recordedChunksRef.current = []
        mediaRecorderRef.current = null
        if (audioTrackRef.current) {
          audioTrackRef.current.stop()
          audioTrackRef.current = null
        }
        // ‚ö†Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ canvas ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏•‡∏ö‡πÄ‡∏õ‡πá‡∏ô canvas ‡∏Ç‡∏≠‡∏á session ‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
        // ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô race condition ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å startRecording() ‡πÉ‡∏´‡∏°‡πà
        if (compositeCanvasRef.current === sessionCanvas) {
          compositeCanvasRef.current = null
        }
      }
    }

    mediaRecorderRef.current.start()
    return true
  }, [])

  /**
   * ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÅ‡∏ö‡∏ö AR (‡∏£‡∏ß‡∏° video + 3D model + decorative elements)
   * ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤ 30 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
   * ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á mp4-muxer (Android/Chrome) ‡πÅ‡∏•‡∏∞ MediaRecorder (browser ‡∏≠‡∏∑‡πà‡∏ô‡πÜ)
   */
  const startRecording = async () => {
    if (!streamRef.current || !horseContainerRef.current) return false

    try {
      // ‡∏™‡∏£‡πâ‡∏≤‡∏á canvas ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö composite - ‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á 9:16
      const canvas = document.createElement('canvas')
      // ‡πÉ‡∏ä‡πâ‡∏Ç‡∏ô‡∏≤‡∏î 720x1280 (9:16 portrait) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏ô AVC level 3.1 limit
      const OUTPUT_WIDTH = 720
      const OUTPUT_HEIGHT = 1280
      canvas.width = OUTPUT_WIDTH
      canvas.height = OUTPUT_HEIGHT
      compositeCanvasRef.current = canvas

      // Capture overlay ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Three.js canvas ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á + decorative elements ‡πÅ‡∏¢‡∏Å
      // ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏õ‡∏∏‡πà‡∏°‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÑ‡∏õ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÄ‡∏ü‡∏£‡∏°
      // ‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á await ‡πÉ‡∏´‡πâ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏° compositeFrame() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô race condition
      let overlayCanvasCache = null
      try {
        // ‡∏™‡∏£‡πâ‡∏≤‡∏á canvas ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö overlay (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ decorative elements, ‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° video ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° 3D model)
        const overlayCanvas = document.createElement('canvas')
        const OUTPUT_WIDTH = 720
        const OUTPUT_HEIGHT = 1280
        overlayCanvas.width = OUTPUT_WIDTH
        overlayCanvas.height = OUTPUT_HEIGHT
        const overlayCtx = overlayCanvas.getContext('2d')

        // ‡∏ß‡∏≤‡∏î decorative elements ‡πÅ‡∏ö‡∏ö deterministic ‡πÉ‡∏ô output 720x1280 (‡πÑ‡∏°‡πà‡∏≠‡∏¥‡∏á DOM)
        const [wishImg, propRImg, propLImg] = await Promise.all([
          loadOverlayImage(selectedWishSrc),
          loadOverlayImage(wishPropRImg),
          loadOverlayImage(wishPropLImg),
        ])
        drawHorseOverlayFixed(overlayCtx, OUTPUT_WIDTH, OUTPUT_HEIGHT, wishImg, propRImg, propLImg)

        // 3. ‡πÑ‡∏°‡πà‡∏ß‡∏≤‡∏î Three.js canvas ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏ß‡∏≤‡∏î‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å frame ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ animation ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        // overlayCanvasCache ‡∏à‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ decorative elements ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô

        overlayCanvasCache = overlayCanvas
        console.log('‚úÖ Decorative elements captured successfully (without buttons and 3D model) for video recording')
      } catch (err) {
        console.error('‚ùå Error capturing overlay:', err)
      }

      // ‡πÄ‡∏Å‡πá‡∏ö overlayCanvasCache ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô closure ‡∏Ç‡∏≠‡∏á compositeFrame
      // ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ compositeFrame ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÑ‡∏î‡πâ

      // ‡∏™‡∏£‡πâ‡∏≤‡∏á compositeFrame function ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á overlayCanvasCache ‡πÑ‡∏î‡πâ
      const compositeFrame = () => {
        if (!compositeCanvasRef.current || !videoRef.current) return

        const ctx = compositeCanvasRef.current.getContext('2d')
        const videoEl = videoRef.current
        const container = horseContainerRef.current

        const OUTPUT_WIDTH = 720
        const OUTPUT_HEIGHT = 1280

        ctx.clearRect(0, 0, OUTPUT_WIDTH, OUTPUT_HEIGHT)

        // 1. ‡∏ß‡∏≤‡∏î video stream ‡∏Å‡πà‡∏≠‡∏ô (‡πÄ‡∏ï‡πá‡∏° canvas 720x1280)
        const videoWidth = videoEl.videoWidth || OUTPUT_WIDTH
        const videoHeight = videoEl.videoHeight || OUTPUT_HEIGHT
        const videoAspect = videoWidth / videoHeight

        // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î video ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡πá‡∏° canvas ‡πÇ‡∏î‡∏¢‡∏¢‡∏∂‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å (9:16)
        let bgWidth = OUTPUT_WIDTH
        let bgHeight = bgWidth / videoAspect
        if (bgHeight < OUTPUT_HEIGHT) {
          bgHeight = OUTPUT_HEIGHT
          bgWidth = bgHeight * videoAspect
        }
        const bgX = (OUTPUT_WIDTH - bgWidth) / 2
        const bgY = (OUTPUT_HEIGHT - bgHeight) / 2

        // Mirror ‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤)
        ctx.save()
        ctx.translate(OUTPUT_WIDTH, 0)
        ctx.scale(-1, 1) // mirror ‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô
        ctx.drawImage(videoEl, bgX, bgY, bgWidth, bgHeight)
        ctx.restore()

        // 2. ‡∏ß‡∏≤‡∏î decorative elements ‡∏à‡∏≤‡∏Å overlayCanvasCache (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° 3D model)
        // overlayCanvasCache ‡∏ñ‡∏π‡∏Å capture ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏° compositeFrame() loop
        if (overlayCanvasCache) {
          // overlayCanvasCache ‡∏°‡∏µ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ decorative elements (wish images, props)
          // ‡∏ß‡∏≤‡∏î‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á scale ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ overlayCanvasCache ‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î 720x1280 ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß)
          ctx.drawImage(overlayCanvasCache, 0, 0, OUTPUT_WIDTH, OUTPUT_HEIGHT)
        }

        // 3. ‡∏ß‡∏≤‡∏î Three.js canvas (3D model) ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å frame ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ animation ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        // ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö noodleverse: ‡πÉ‡∏ä‡πâ canvas size ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡πá‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á
        const threeCanvasEl = threeCanvasRef.current
        if (threeCanvasEl && threeCanvasEl.width > 0 && threeCanvasEl.height > 0) {
          const arAspectRatio = threeCanvasEl.width / threeCanvasEl.height
          const drawHeight = OUTPUT_HEIGHT
          const drawWidth = drawHeight * arAspectRatio
          const drawX = (OUTPUT_WIDTH - drawWidth) / 2
          ctx.drawImage(threeCanvasEl, drawX, 0, drawWidth, drawHeight)
        } else {
          // Fallback: ‡∏•‡∏≠‡∏á query ‡∏à‡∏≤‡∏Å DOM
          const modelFrame = container?.querySelector('.model-frame')
          if (modelFrame) {
            const fallbackCanvas = modelFrame.querySelector('canvas')
            if (fallbackCanvas && fallbackCanvas.width > 0 && fallbackCanvas.height > 0) {
              const arAspectRatio = fallbackCanvas.width / fallbackCanvas.height
              const drawHeight = OUTPUT_HEIGHT
              const drawWidth = drawHeight * arAspectRatio
              const drawX = (OUTPUT_WIDTH - drawWidth) / 2
              ctx.drawImage(fallbackCanvas, drawX, 0, drawWidth, drawHeight)
            }
          }
        }

        // ‡πÉ‡∏ä‡πâ isRecordingRef ‡πÅ‡∏ó‡∏ô isRecording ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ‡∏Ñ‡πà‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        if (isRecordingRef.current) {
          recordingAnimationFrameRef.current = requestAnimationFrame(compositeFrame)
        }
      }

      const androidChrome = isAndroid() && isChrome()

      // ‚ö†Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ isRecording ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏° compositeFrame loop ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å overlayCanvasCache ‡∏ñ‡∏π‡∏Å capture ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß
      // ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô race condition ‡∏ó‡∏µ‡πà overlayCanvasCache ‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô null
      setIsRecording(true)
      isRecordingRef.current = true

      // ‡πÄ‡∏£‡∏¥‡πà‡∏° composite frame loop (overlayCanvasCache ‡∏ñ‡∏π‡∏Å capture ‡πÅ‡∏•‡πâ‡∏ß)
      compositeFrame()

      if (androidChrome) {
        console.log("Using mp4-muxer for Android/Chrome")
        const success = await startRecordingWithMuxer()
        if (success) {
          recordingTimeoutRef.current = setTimeout(() => {
            stopRecording()
          }, 30000)
        } else {
          // ‡∏ñ‡πâ‡∏≤ startRecordingWithMuxer ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î recording
          setIsRecording(false)
          isRecordingRef.current = false
          if (recordingAnimationFrameRef.current) {
            cancelAnimationFrame(recordingAnimationFrameRef.current)
            recordingAnimationFrameRef.current = null
          }
        }
        return success
      } else {
        console.log("Using MediaRecorder for other browsers")
        const success = await startRecordingWithMediaRecorder()
        if (success) {
          recordingTimeoutRef.current = setTimeout(() => {
            stopRecording()
          }, 30000)
        } else {
          // ‡∏ñ‡πâ‡∏≤ startRecordingWithMediaRecorder ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î recording
          setIsRecording(false)
          isRecordingRef.current = false
          if (recordingAnimationFrameRef.current) {
            cancelAnimationFrame(recordingAnimationFrameRef.current)
            recordingAnimationFrameRef.current = null
          }
        }
        return success
      }
    } catch (err) {
      console.error("Failed to start recording:", err)
      setCameraError('‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏≠‡∏±‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÑ‡∏î‡πâ')
      return false
    }
  }

  /**
   * ‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
   */
  const stopRecording = async () => {
    const androidChrome = isAndroid() && isChrome()

    // ‡∏´‡∏¢‡∏∏‡∏î timeout ‡πÅ‡∏•‡∏∞ animation frame
    if (recordingTimeoutRef.current) {
      clearTimeout(recordingTimeoutRef.current)
      recordingTimeoutRef.current = null
    }

    if (recordingAnimationFrameRef.current) {
      cancelAnimationFrame(recordingAnimationFrameRef.current)
      recordingAnimationFrameRef.current = null
    }

    if (androidChrome) {
      // ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏î‡∏î‡πâ‡∏ß‡∏¢ Muxer
      if (isRecordingRef.current) {
        isRecordingRef.current = false
        clearTimeout(recordingTimeoutRef.current)
        cancelAnimationFrame(recordingAnimationFrameRef.current)

        setIsProcessing(true)

        // ‡πÉ‡∏ä‡πâ requestAnimationFrame wrapper ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤ frame ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ñ‡∏π‡∏Å encode ‡πÅ‡∏•‡πâ‡∏ß
        requestAnimationFrame(async () => {
          console.log("Processing video file with muxer...")

          try {
            if (videoEncoderRef.current?.state === 'configured') {
              await videoEncoderRef.current.flush().catch(console.error)
            }
            if (audioEncoderRef.current?.state === 'configured') {
              await audioEncoderRef.current.flush().catch(console.error)
            }

            if (muxerRef.current) {
              muxerRef.current.finalize()
              const { buffer } = muxerRef.current.target
              const videoBlob = new Blob([buffer], { type: 'video/mp4' })
              const videoUrl = URL.createObjectURL(videoBlob)
              setPreview({ type: 'video', url: videoUrl, mimeType: 'video/mp4' })
              console.log(`‚úÖ Video recorded successfully with muxer: ${(videoBlob.size / 1024 / 1024).toFixed(2)}MB`)
            }
          } catch (error) {
            console.error("Error processing video:", error)
            setCameraError("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
          } finally {
            // Cleanup audio stream ‡πÅ‡∏•‡∏∞ nodes
            if (audioProcessorNodeRef.current) {
              audioProcessorNodeRef.current.disconnect()
              audioProcessorNodeRef.current = null
            }
            if (audioSourceNodeRef.current) {
              audioSourceNodeRef.current.disconnect()
              audioSourceNodeRef.current = null
            }
            if (audioStreamRef.current) {
              audioStreamRef.current.getTracks().forEach(track => track.stop())
              audioStreamRef.current = null
            }
            if (audioTrackRef.current) {
              audioTrackRef.current.stop()
              audioTrackRef.current = null
            }

            // Cleanup refs
            videoEncoderRef.current = null
            audioEncoderRef.current = null
            muxerRef.current = null
            setIsProcessing(false)
            setIsRecording(false)
          }
        })
      }
    } else {
      // ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö MediaRecorder
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
        // ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å - onstop event ‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ preview ‡πÅ‡∏•‡∏∞ setIsRecording(false)
        mediaRecorderRef.current.stop()
      } else {
        // ‡∏ñ‡πâ‡∏≤ MediaRecorder ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏¢‡∏∏‡∏î‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ set state ‡πÄ‡∏õ‡πá‡∏ô false
        setIsRecording(false)
        isRecordingRef.current = false
      }
    }
  }

  /**
   * ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û/‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
   * ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ capturePhoto ‡∏´‡∏£‡∏∑‡∏≠ startRecording/stopRecording ‡∏ï‡∏≤‡∏°‡πÇ‡∏´‡∏°‡∏î
   */
  const handleCapture = () => {
    // ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏ñ‡πà‡∏≤‡∏¢‡∏ã‡πâ‡∏≥‡∏Ç‡∏ì‡∏∞‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    if (isProcessing) {
      return
    }

    if (captureMode === 'photo') {
      capturePhoto()
    } else if (captureMode === 'video') {
      if (isRecording) {
        stopRecording()
      } else {
        startRecording()
      }
    }
  }

  /**
   * ‡∏õ‡∏¥‡∏î preview modal
   */
  const handleSave = async () => {
    if (!preview.url) return

    try {
      const link = document.createElement('a')
      link.href = preview.url

      if (preview.type === 'photo') {
        link.download = `lucky-seemsee-${Date.now()}.png`
      } else {
        link.download = `lucky-seemsee-${Date.now()}.mp4`
      }

      document.body.appendChild(link)
      link.click()
      document.body.removeChild(link)
    } catch (error) {
      console.error('Error saving file:', error)
      setCameraError('‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ')
    }
  }

  /**
   * ‡πÅ‡∏ä‡∏£‡πå‡∏†‡∏≤‡∏û/‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
   */
  const handleShare = async () => {
    if (!preview.url) return

    try {
      if (navigator.share && navigator.canShare) {
        const response = await fetch(preview.url)
        const blob = await response.blob()
        const file = new File(
          [blob],
          preview.type === 'photo'
            ? `lucky-seemsee-${Date.now()}.png`
            : `lucky-seemsee-${Date.now()}.mp4`,
          { type: preview.type === 'photo' ? 'image/png' : 'video/mp4' }
        )

        const shareData = { files: [file] }

        if (navigator.canShare(shareData)) {
          await navigator.share(shareData)
        } else {
          handleSave()
        }
      } else {
        handleSave()
      }
    } catch (error) {
      if (error.name !== 'AbortError') {
        console.error('Error sharing file:', error)
        handleSave()
      }
    }
  }

  /**
   * ‡πÄ‡∏•‡πà‡∏ô‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á (retry)
   * ‡∏õ‡∏¥‡∏î preview ‡πÅ‡∏•‡∏∞‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å
   */
  const handleRetry = () => {
    setPreview({ type: null, url: null })
    goHome()
  }

  // ============================================
  // RENDER
  // ============================================

  if (view === 'home') {
    return (
      <CameraStage videoRef={videoRef}>
        <HomeScreen onHorse={goToHorse} onShake={goToShake} cameraError={cameraError} />
      </CameraStage>
    )
  }

  if (view === 'horse') {
    return (
      <CameraStage videoRef={videoRef}>
        <HorseScreen
          onBack={goHome}
          captureMode={captureMode}
          setCaptureMode={(mode) => {
            if (!isRecording && !isProcessing) setCaptureMode(mode)
          }}
          isRecording={isRecording}
          isProcessing={isProcessing}
          handleCapture={handleCapture}
          preview={preview}
          cameraError={cameraError}
          modelSrc={horseModel}
          selectedWishSrc={selectedWishSrc}
          containerRef={horseContainerRef}
          threeCanvasRef={threeCanvasRef}
          onSave={handleSave}
          onShare={handleShare}
          onRetry={handleRetry}
        />
      </CameraStage>
    )
  }

  if (view === 'fortune') {
    const headList = [head1, head2, head3, head4, head5]
    const textList = [text1, text2, text3, text4, text5]
    const idx = fortuneIndex ?? 0
    return (
      <CameraStage videoRef={videoRef}>
        <FortuneScreen
          onBack={goHome}
          onConfirm={(type) => {
            if (type === 'wallpaper') {
              goToWallpaper()
            }
          }}
          headSrc={headList[idx]}
          textSrc={textList[idx]}
        />
      </CameraStage>
    )
  }

  if (view === 'wallpaper') {
    return (
      <CameraStage videoRef={videoRef}>
        <WallpaperScreen
          onBack={goHome}
          onCreate={handleCreateAiWallpaper}
          onPlayAgain={handleAiWallpaperPlayAgain}
          isGenerating={aiWallpaperStatus === 'generating'}
          aiResult={aiWallpaperStatus === 'ready' ? aiWallpaperResult : null}
          aiError={aiWallpaperStatus === 'error' ? aiWallpaperError : ''}
          topicOptions={WALLPAPER_TOPIC_OPTIONS}
          zodiacOptions={WALLPAPER_ZODIAC_OPTIONS}
          selectedTopic={selectedTopic}
          selectedZodiac={selectedZodiac}
          setSelectedTopic={setSelectedTopic}
          setSelectedZodiac={setSelectedZodiac}
        />
      </CameraStage>
    )
  }

  return (
    <CameraStage videoRef={videoRef}>
      <ShakeScreen
        onBack={goHome}
        shakeTrigger={shakeTrigger}
        onSequenceDone={goToFortune}
      />
    </CameraStage>
  )
}

export default App
